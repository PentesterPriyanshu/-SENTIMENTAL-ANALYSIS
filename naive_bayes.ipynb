{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform Sentiment Analysis using Naive Bayes Algorithm\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing necessary libraries \n",
    "import math \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# NLP Libraries \n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Tweets Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset \n",
    "df = pd.read_csv(\"dattwitter_a.csv\", encoding=\"latin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform Basic Pre-Processing and  Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1599999 entries, 0 to 1599998\n",
      "Data columns (total 6 columns):\n",
      " #   Column                                                                                                               Non-Null Count    Dtype \n",
      "---  ------                                                                                                               --------------    ----- \n",
      " 0   0                                                                                                                    1599999 non-null  int64 \n",
      " 1   1467810369                                                                                                           1599999 non-null  int64 \n",
      " 2   Mon Apr 06 22:19:45 PDT 2009                                                                                         1599999 non-null  object\n",
      " 3   NO_QUERY                                                                                                             1599999 non-null  object\n",
      " 4   _TheSpecialOne_                                                                                                      1599999 non-null  object\n",
      " 5   @switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D  1599999 non-null  object\n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 73.2+ MB\n",
      "\n",
      "Printing the  first five rows of the dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1467810369</th>\n",
       "      <th>Mon Apr 06 22:19:45 PDT 2009</th>\n",
       "      <th>NO_QUERY</th>\n",
       "      <th>_TheSpecialOne_</th>\n",
       "      <th>@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811372</td>\n",
       "      <td>Mon Apr 06 22:20:00 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>joy_wolf</td>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY _TheSpecialOne_  \\\n",
       "0  0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   scotthamilton   \n",
       "1  0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY        mattycus   \n",
       "2  0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY         ElleCTF   \n",
       "3  0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY          Karoli   \n",
       "4  0  1467811372  Mon Apr 06 22:20:00 PDT 2009  NO_QUERY        joy_wolf   \n",
       "\n",
       "  @switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D  \n",
       "0  is upset that he can't update his Facebook by ...                                                                   \n",
       "1  @Kenichan I dived many times for the ball. Man...                                                                   \n",
       "2    my whole body feels itchy and like its on fire                                                                    \n",
       "3  @nationwideclass no, it's not behaving at all....                                                                   \n",
       "4                      @Kwesidei not the whole crew                                                                    "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Information about dataset \n",
    "df.info()\n",
    "print(\"\\nPrinting the  first five rows of the dataset:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataset is -\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1600000, 6)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Rename columns and reading dataset again\n",
    "column_names = ['target','id','date','flag','user','text']\n",
    "df= pd.read_csv('dattwitter_a.csv',names = column_names, encoding = 'latin')\n",
    "\n",
    "# Printing the shape of dataset\n",
    "print(\"Shape of the dataset is -\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1600000 entries, 0 to 1599999\n",
      "Data columns (total 6 columns):\n",
      " #   Column  Non-Null Count    Dtype \n",
      "---  ------  --------------    ----- \n",
      " 0   target  1600000 non-null  int64 \n",
      " 1   id      1600000 non-null  int64 \n",
      " 2   date    1600000 non-null  object\n",
      " 3   flag    1600000 non-null  object\n",
      " 4   user    1600000 non-null  object\n",
      " 5   text    1600000 non-null  object\n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 73.2+ MB\n",
      "\n",
      "Printing the  first five rows of the dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target          id                          date      flag  \\\n",
       "0       0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1       0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2       0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3       0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4       0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "\n",
       "              user                                               text  \n",
       "0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1    scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "2         mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "3          ElleCTF    my whole body feels itchy and like its on fire   \n",
       "4           Karoli  @nationwideclass no, it's not behaving at all....  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Again checking the info of dataset \n",
    "df.info()\n",
    "print(\"\\nPrinting the  first five rows of the dataset:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target    0\n",
       "id        0\n",
       "date      0\n",
       "flag      0\n",
       "user      0\n",
       "text      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking if any null values present or not \n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    800000\n",
       "1    800000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CONVERT TARGET 4 TO 1\n",
    "df.replace({'target':{4:1}}, inplace=True)\n",
    "\n",
    "# Again checking class distribution of target column\n",
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target                                               text\n",
       "0       0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
       "1       0  is upset that he can't update his Facebook by ...\n",
       "2       0  @Kenichan I dived many times for the ball. Man...\n",
       "3       0    my whole body feels itchy and like its on fire \n",
       "4       0  @nationwideclass no, it's not behaving at all...."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dropping the rest of the column other than target and text \n",
    "df.drop(['id','date','flag','user'],axis=1,inplace=True)\n",
    "\n",
    "# Again printing the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1600000 entries, 0 to 1599999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count    Dtype \n",
      "---  ------  --------------    ----- \n",
      " 0   target  1600000 non-null  int64 \n",
      " 1   text    1600000 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 24.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taking the Tweets  from Original Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let split the dataset into smaller dataset \n",
    "\n",
    "# Creating a copy of dataframe df , named new_df which contains only 100000 examples\n",
    "\n",
    "new_dataframe_class_0 = df[df['target'] == 0].head(500)\n",
    "new_dataframe_class_1 = df[df['target'] == 1].head(500)\n",
    "\n",
    "# Concatenate the two subsets to create the final DataFrame with equal counts of both classes\n",
    "new_df = pd.concat([new_dataframe_class_0, new_dataframe_class_1])\n",
    "\n",
    "# Shuffle the rows to randomize the order\n",
    "new_df = new_df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   target  1000 non-null   int64 \n",
      " 1   text    1000 non-null   object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 15.8+ KB\n",
      "\n",
      "Printing some tweets of the dataset: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>@markegli &amp;amp; @kariegli the dinner menu this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>My man crush Jake Peavy let me down  #gayforpeavy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>I'm so upset that I missed my chat and quiz on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>@pjaficionado  Having fun, loving life, happy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>That was sick. Soma rocks.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target                                               text\n",
       "0       1  @markegli &amp; @kariegli the dinner menu this...\n",
       "1       0  My man crush Jake Peavy let me down  #gayforpeavy\n",
       "2       0  I'm so upset that I missed my chat and quiz on...\n",
       "3       1  @pjaficionado  Having fun, loving life, happy ...\n",
       "4       1                        That was sick. Soma rocks. "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking info about newly created dataset \n",
    "new_df.info()\n",
    "\n",
    "print(\"\\nPrinting some tweets of the dataset: \")\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starting the Data Pre-processing part with the help of NLTK library\n",
    "-> Here i exclude these set of words ['not', 'no', 'against', 'nor'] from stopword , because they contribute in learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'how', \"hasn't\", 'did', 'very', 'herself', 'just', 'isn', 'to', 'than', 'further', 'ain', 'these', 'what', \"mightn't\", 'been', \"hadn't\", 'down', \"she's\", 'after', 'them', 've', 'had', 'on', \"haven't\", 'her', 'she', \"doesn't\", 'other', 'didn', 'any', 'ourselves', \"didn't\", 'haven', 'is', 'are', 'up', 'were', 'own', 'm', \"don't\", 'both', 'be', 'hasn', \"shan't\", 'his', 'above', 'at', 'before', 'yours', 'wouldn', 'me', 'do', \"shouldn't\", 'and', 'about', 'same', \"you'll\", 'can', \"you're\", 'between', \"that'll\", 'under', 'until', 'wasn', 'so', \"you'd\", 'has', 'but', 'needn', 'or', 'because', 'all', \"needn't\", 'while', 'too', 'am', 'y', 'more', 'why', 'through', 'hers', \"it's\", 'most', 'd', 'its', 'with', 'off', 'couldn', 'of', 'they', 'having', 'then', 'yourselves', \"wouldn't\", 'that', 'weren', \"won't\", 'few', 'himself', 'only', 'from', 'will', 'some', 'as', 't', 'don', 'll', 'should', 'your', 'this', 'does', 'mustn', 'in', 'a', 'where', 'yourself', 'again', 'who', 'won', 'ours', 'him', 'each', \"couldn't\", \"isn't\", 'out', 'by', 'doing', 'once', \"wasn't\", 'our', 'have', \"aren't\", 'shouldn', 'those', 'an', 'the', 'such', \"should've\", \"you've\", \"mustn't\", 's', 're', 'it', 'itself', 'i', 'which', 'you', 'my', 'ma', 'doesn', 'he', 'during', 'we', 'mightn', 'whom', 'their', 'was', 'over', 'themselves', 'theirs', 'below', 'for', 'when', 'aren', 'there', 'myself', 'being', 'if', 'into', \"weren't\", 'o', 'shan', 'hadn', 'here', 'now'}\n"
     ]
    }
   ],
   "source": [
    "# Get the default NLTK stopwords list\n",
    "default_stopwords = set(stopwords.words('english'))\n",
    "\n",
    "# Add additional stopwords that you want to keep (e.g., negation words)\n",
    "custom_stopwords = set(['not', 'no', 'against', 'nor'])\n",
    "\n",
    "# Create a set that excludes words in custom_stopwords from default_stopwords\n",
    "final_stopwords = default_stopwords - custom_stopwords\n",
    "\n",
    "print(final_stopwords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates an instance of the PorterStemmer.\n",
    "port_stem = PorterStemmer()\n",
    "\n",
    "# Define the Stemming Function and perform operations \n",
    "def stemming(content):\n",
    "    # Remove non-alphabetic characters using regular expression\n",
    "    stemmed_content = re.sub('[^a-zA-Z]', ' ', content)\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    stemmed_content = stemmed_content.lower()\n",
    "    \n",
    "    # Tokenize the text into words\n",
    "    stemmed_content = stemmed_content.split()\n",
    "    \n",
    "    # Apply stemming using Porter Stemmer, and exclude stopwords\n",
    "    stemmed_content = [port_stem.stem(word) for word in stemmed_content if not word in final_stopwords]\n",
    "    \n",
    "    # Join the stemmed words into a single string\n",
    "    stemmed_content = ' '.join(stemmed_content)\n",
    "    \n",
    "    return stemmed_content\n",
    "\n",
    "# Applies the stemming function to the 'text' column of the DataFrame and creates a new column 'stemmed_content' containing the preprocessed text.\n",
    "new_df['stemmed_content'] = new_df['text'].apply(stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "      <th>stemmed_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>@markegli &amp;amp; @kariegli the dinner menu this...</td>\n",
       "      <td>markegli amp kariegli dinner menu week someth ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>My man crush Jake Peavy let me down  #gayforpeavy</td>\n",
       "      <td>man crush jake peavi let gayforpeavi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>I'm so upset that I missed my chat and quiz on...</td>\n",
       "      <td>upset miss chat quiz onlin free internet ceas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>@pjaficionado  Having fun, loving life, happy ...</td>\n",
       "      <td>pjaficionado fun love life happi game everyth ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>That was sick. Soma rocks.</td>\n",
       "      <td>sick soma rock</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target                                               text  \\\n",
       "0       1  @markegli &amp; @kariegli the dinner menu this...   \n",
       "1       0  My man crush Jake Peavy let me down  #gayforpeavy   \n",
       "2       0  I'm so upset that I missed my chat and quiz on...   \n",
       "3       1  @pjaficionado  Having fun, loving life, happy ...   \n",
       "4       1                        That was sick. Soma rocks.    \n",
       "\n",
       "                                     stemmed_content  \n",
       "0  markegli amp kariegli dinner menu week someth ...  \n",
       "1               man crush jake peavi let gayforpeavi  \n",
       "2      upset miss chat quiz onlin free internet ceas  \n",
       "3  pjaficionado fun love life happi game everyth ...  \n",
       "4                                     sick soma rock  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Again Printing the pre-processed data \n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 3 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   target           1000 non-null   int64 \n",
      " 1   text             1000 non-null   object\n",
      " 2   stemmed_content  1000 non-null   object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 23.6+ KB\n"
     ]
    }
   ],
   "source": [
    "new_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Separate positive and negative tweets\n",
    "positive_tweets = new_df[new_df['target'] == 1]\n",
    "negative_tweets = new_df[new_df['target'] == 0]\n",
    "\n",
    "# Function to generate and plot word clouds\n",
    "def generate_word_cloud(data, sentiment):\n",
    "    all_text = ' '.join(data['stemmed_content'])\n",
    "    \n",
    "# Generate word clouds for positive and negative tweets\n",
    "generate_word_cloud(positive_tweets, 'Positive')\n",
    "generate_word_cloud(negative_tweets, 'Negative')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Frequency Table from the processed tweets dataset(which is done in above cell)\n",
    "    -> Table contains three columns named - unique_word , positive , negative "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  unique_word positive negative total\n",
      "0       sound        2        2     4\n",
      "0        mail        2        3     5\n",
      "0       parti        1        5     6\n",
      "0       reduc        1        2     3\n",
      "0         fli        4        2     6\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Create a list of all unique words\n",
    "all_words = ' '.join(new_df['stemmed_content']).split()\n",
    "unique_words = set(all_words)\n",
    "\n",
    "# Step 2: Create an empty DataFrame to store word frequencies\n",
    "word_freq_df = pd.DataFrame(columns=['unique_word', 'positive', 'negative'])\n",
    "\n",
    "# Step 3: Count word frequencies for positive (target=1) and negative (target=0) labeled tweets\n",
    "for word in unique_words:\n",
    "    positive_count = sum((new_df['target'] == 1) & (new_df['stemmed_content'].str.contains(word)))\n",
    "    negative_count = sum((new_df['target'] == 0) & (new_df['stemmed_content'].str.contains(word)))\n",
    "    \n",
    "    word_freq_df = pd.concat([word_freq_df, pd.DataFrame({'unique_word': [word], 'positive': [positive_count], 'negative': [negative_count]})])\n",
    "\n",
    "# Optional: You can add a column for total frequency if needed\n",
    "word_freq_df['total'] = word_freq_df['positive'] + word_freq_df['negative']\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(word_freq_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count the total unique words in the whole dataset , sum of positive frequency , and sum of negative frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of positive values: 14041\n",
      "Sum of negative values: 13482\n",
      "Count of total unique words: 3035\n"
     ]
    }
   ],
   "source": [
    "# Sum of values in the 'positive' and 'negative' columns\n",
    "sum_positive = word_freq_df['positive'].sum()\n",
    "sum_negative = word_freq_df['negative'].sum()\n",
    "\n",
    "# Count of total unique words\n",
    "total_unique_words = len(word_freq_df)\n",
    "\n",
    "# Append a new row with sums and count to the last row of the DataFrame\n",
    "word_freq_df.loc[len(word_freq_df)] = {'unique_word': 'Total', 'positive': sum_positive, 'negative': sum_negative, 'total': total_unique_words}\n",
    "\n",
    "\n",
    "# Display the results\n",
    "print(f\"Sum of positive values: {sum_positive}\")\n",
    "print(f\"Sum of negative values: {sum_negative}\")\n",
    "print(f\"Count of total unique words: {total_unique_words}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     unique_word positive negative total\n",
      "0          sound        2        2     4\n",
      "0           mail        2        3     5\n",
      "0          parti        1        5     6\n",
      "0          reduc        1        2     3\n",
      "0            fli        4        2     6\n",
      "...          ...      ...      ...   ...\n",
      "0        muahaha        0        1     1\n",
      "0            hin       35       38    73\n",
      "0         moment        4        0     4\n",
      "0       boundari        1        0     1\n",
      "3035       Total    14041    13482  3035\n",
      "\n",
      "[3036 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Display the updated DataFrame\n",
    "print(word_freq_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performing the Laplace Smoothing (so that we do not come with  zero probabilities for any words to any class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  unique_word positive negative total  P(w|pos)  P(w|neg)\n",
      "0       sound        2        2     4  0.000176  0.000182\n",
      "0        mail        2        3     5  0.000176  0.000242\n",
      "0       parti        1        5     6  0.000117  0.000363\n",
      "0       reduc        1        2     3  0.000117  0.000182\n",
      "0         fli        4        2     6  0.000293  0.000182\n"
     ]
    }
   ],
   "source": [
    "# Smoothing parameter (Laplacian smoothing)\n",
    "alpha = 1\n",
    "\n",
    "# Calculate conditional probabilities for each word\n",
    "word_freq_df['P(w|pos)'] = (word_freq_df['positive'] + alpha) / (sum_positive +  total_unique_words)\n",
    "word_freq_df['P(w|neg)'] = (word_freq_df['negative'] + alpha) / (sum_negative +  total_unique_words)\n",
    "\n",
    "# Display the updated DataFrame with conditional probabilities\n",
    "print(word_freq_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step - 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating lambda score (log Likelihood) for each unique words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  unique_word positive negative total  P(w|pos)  P(w|neg)  lambda_score\n",
      "0       sound        2        2     4  0.000176  0.000182     -0.033284\n",
      "0        mail        2        3     5  0.000176  0.000242     -0.320966\n",
      "0       parti        1        5     6  0.000117  0.000363     -1.131896\n",
      "0       reduc        1        2     3  0.000117  0.000182     -0.438749\n",
      "0         fli        4        2     6  0.000293  0.000182      0.477542\n"
     ]
    }
   ],
   "source": [
    "# Laplacian smoothing function\n",
    "def laplacian_smoothing(positive_freq, negative_freq, total_unique_words):\n",
    "    smoothing_factor = 1  # Laplacian smoothing factor\n",
    "    \n",
    "    # Calculate conditional probabilities using Laplacian smoothing\n",
    "    prob_pos = (positive_freq + smoothing_factor) / (sum_positive + total_unique_words)\n",
    "    prob_neg = (negative_freq + smoothing_factor) / (sum_negative + total_unique_words)\n",
    "    \n",
    "    # Calculate probability ratio\n",
    "    ratio_w = prob_pos / prob_neg\n",
    "    \n",
    "    # Compute lambda score\n",
    "    lambda_w = np.log(ratio_w)\n",
    "    \n",
    "    return lambda_w\n",
    "\n",
    "# Apply Laplacian smoothing and compute lambda score for each word\n",
    "word_freq_df['lambda_score'] = word_freq_df.apply(\n",
    "    lambda row: laplacian_smoothing(row['positive'], row['negative'], total_unique_words),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "word_freq_df.to_csv('frequency.csv', index=False)\n",
    "\n",
    "# Display the updated DataFrame with lambda scores\n",
    "print(word_freq_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step - 4 (Optional , if dataset is balanced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute the Log Prior "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive tweets: 500\n",
      "Number of negative tweets: 500\n",
      "Ratio of positive to negative tweets: 1.0\n",
      "Log prior: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Count the number of positive and negative tweets\n",
    "num_positive_tweets = sum(new_df['target'] == 1)\n",
    "num_negative_tweets = sum(new_df['target'] == 0)\n",
    "\n",
    "# Step 2: Calculate the ratio of positive to negative tweets\n",
    "ratio_pos_neg = num_positive_tweets / num_negative_tweets\n",
    "\n",
    "# Step 3: Calculate the log prior\n",
    "log_prior = np.log(ratio_pos_neg)\n",
    "\n",
    "# Step 4: Save the computed log prior value in a .txt file\n",
    "with open('log_prior.txt', 'w') as file:\n",
    "    file.write(str(log_prior))\n",
    "\n",
    "# Display the results\n",
    "print(f\"Number of positive tweets: {num_positive_tweets}\")\n",
    "print(f\"Number of negative tweets: {num_negative_tweets}\")\n",
    "print(f\"Ratio of positive to negative tweets: {ratio_pos_neg}\")\n",
    "print(f\"Log prior: {log_prior}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formulas in which we work and calculate the values in the above cells are : - \n",
    " 1.) Bayes Theorem -\n",
    "        P(X|Y) = P(Y|X) × P(X)P(Y)\n",
    "\n",
    " 2.) Laplace smoothing - \n",
    "        P(W_class) = freq(wi,class) + 1/ N_class + V\n",
    "\n",
    "        ∏{ i=1 -> m } P(wi|pos) / P(wi|neg)\n",
    "\n",
    " 3.) Log Likelihood - \n",
    "        ratio(wi) = P(wi|pos) / P(wi|neg)\n",
    "\n",
    "        to prevent numerical underflow we use this instead of above  formula:\n",
    "                log likelihood = λ(w) = log(w|pos) / log(w|neg)\n",
    "\n",
    " 4.) Log Prior - \n",
    "        log prior = log(P(D_pos) / P(D_neg)) = log(D_pos)- log(D_neg)\n",
    "\n",
    " 5.)  Final Formula - \n",
    "        p = log prior + ∑{i=1 -> N} log likelihood(w_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing phase of Naive Bayes Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> Loading the word_frequency file into dataframe .\n",
    "#\n",
    "-> calulate log_prior "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_freq_df = pd.read_csv(\"frequency.csv\")\n",
    "\n",
    "# Step 1: Count the number of positive and negative tweets\n",
    "num_positive_tweets = sum(new_df['target'] == 1)\n",
    "num_negative_tweets = sum(new_df['target'] == 0)\n",
    "\n",
    "# Step 2: Calculate the ratio of positive to negative tweets\n",
    "ratio_pos_neg = num_positive_tweets / num_negative_tweets\n",
    "\n",
    "# Step 3: Calculate the log prior\n",
    "log_prior = np.log(ratio_pos_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a tweet:  i am in deperation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative sentiment!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 1: Preprocess the input tweet\n",
    "def preprocess_input_tweet(input_tweet):\n",
    "    # Apply the same preprocessing steps as the training data\n",
    "    stemmed_input = stemming(input_tweet)\n",
    "    return stemmed_input\n",
    "\n",
    "# Step 2: Calculate log likelihood\n",
    "def calculate_log_likelihood(stemmed_input, word_freq_df):\n",
    "    # Split the input into words\n",
    "    words = stemmed_input.split()\n",
    "\n",
    "    # Initialize likelihoods\n",
    "    log_likelihood_pos = 0\n",
    "    log_likelihood_neg = 0\n",
    "\n",
    "    # Iterate through words and calculate log likelihood\n",
    "    for word in words:\n",
    "        if word in word_freq_df['unique_word'].values:\n",
    "            # Get the lambda score for the word\n",
    "            lambda_w = word_freq_df.loc[word_freq_df['unique_word'] == word, 'lambda_score'].values[0]\n",
    "            \n",
    "            # Update log likelihoods\n",
    "            log_likelihood_pos += lambda_w if lambda_w > 0 else 0\n",
    "            log_likelihood_neg += -lambda_w if lambda_w < 0 else 0\n",
    "\n",
    "    return log_likelihood_pos, log_likelihood_neg\n",
    "\n",
    "# Step 3: Make predictions\n",
    "def predict_sentiment(log_likelihood_pos, log_likelihood_neg, log_prior):\n",
    "    # Calculate the final log likelihoods\n",
    "    log_likelihood_pos += log_prior\n",
    "    log_likelihood_neg += log_prior\n",
    "\n",
    "    # Determine the predicted sentiment class\n",
    "    predicted_class = 1 if log_likelihood_pos > log_likelihood_neg else 0\n",
    "\n",
    "    return predicted_class\n",
    "\n",
    "# Get input tweet from the user\n",
    "input_tweet = input(\"Enter a tweet: \")\n",
    "\n",
    "# Preprocess the input tweet\n",
    "preprocessed_input = preprocess_input_tweet(input_tweet)\n",
    "\n",
    "# Calculate log likelihoods\n",
    "log_likelihood_pos, log_likelihood_neg = calculate_log_likelihood(preprocessed_input, word_freq_df)\n",
    "\n",
    "# Make predictions\n",
    "predicted_class = predict_sentiment(log_likelihood_pos, log_likelihood_neg, log_prior)\n",
    "\n",
    "# Display the result\n",
    "if predicted_class == 1:\n",
    "    print(\"Positive sentiment!\")\n",
    "else:\n",
    "    print(\"Negative sentiment!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking Accuracy on unseen tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on remaining tweets: 70.36%\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame with the remaining tweets for testing\n",
    "remaining_tweets = df[~df.index.isin(new_df.index)].head(5000)\n",
    "\n",
    "# Create a new column for predicted labels in the remaining_tweets DataFrame\n",
    "remaining_tweets['predicted_target'] = remaining_tweets['text'].apply(lambda tweet: predict_sentiment(*calculate_log_likelihood(preprocess_input_tweet(tweet), word_freq_df), log_prior=log_prior))\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = sum(remaining_tweets['target'] == remaining_tweets['predicted_target']) / len(remaining_tweets)\n",
    "\n",
    "# Display the accuracy \n",
    "print(f\"Accuracy on remaining tweets: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing of saved model on User input tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# Load the precomputed data and models\n",
    "loaded_word_freq_df = pd.read_csv('frequency.csv')\n",
    "# loaded_log_prior = log_prior\n",
    "with open('log_prior.txt', 'r') as file:\n",
    "        loaded_log_prior = float(file.read())\n",
    "\n",
    "# Define the Stemming Function\n",
    "def stemming(content):\n",
    "    # Remove non-alphabetic characters using regular expression\n",
    "    stemmed_content = re.sub('[^a-zA-Z]', ' ', content)\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    stemmed_content = stemmed_content.lower()\n",
    "    \n",
    "    # Tokenize the text into words\n",
    "    stemmed_content = stemmed_content.split()\n",
    "    \n",
    "    # Apply stemming using Porter Stemmer, and exclude stopwords\n",
    "    final_stopwords = set(stopwords.words('english')) - set(['not', 'no', 'against', 'nor'])\n",
    "    port_stem = PorterStemmer()\n",
    "    stemmed_content = [port_stem.stem(word) for word in stemmed_content if not word in final_stopwords]\n",
    "    \n",
    "    # Join the stemmed words into a single string\n",
    "    stemmed_content = ' '.join(stemmed_content)\n",
    "    \n",
    "    return stemmed_content\n",
    "\n",
    "# Define the log likelihood calculation function\n",
    "def calculate_log_likelihood(stemmed_input):\n",
    "    # Split the input into words\n",
    "    words = stemmed_input.split()\n",
    "\n",
    "    # Initialize likelihoods\n",
    "    log_likelihood_pos = 0\n",
    "    log_likelihood_neg = 0\n",
    "\n",
    "    # Iterate through words and calculate log likelihood\n",
    "    for word in words:\n",
    "        if word in loaded_word_freq_df['unique_word'].values:\n",
    "            # Get the lambda score for the word\n",
    "            lambda_w = loaded_word_freq_df.loc[loaded_word_freq_df['unique_word'] == word, 'lambda_score'].values[0]\n",
    "\n",
    "            # Update log likelihoods\n",
    "            log_likelihood_pos += lambda_w if lambda_w > 0 else 0\n",
    "            log_likelihood_neg += -lambda_w if lambda_w < 0 else 0\n",
    "\n",
    "    return log_likelihood_pos, log_likelihood_neg\n",
    "\n",
    "# Define the prediction function\n",
    "def predict_sentiment(log_likelihood_pos, log_likelihood_neg):\n",
    "    # Calculate the final log likelihoods\n",
    "    log_likelihood_pos += loaded_log_prior\n",
    "    log_likelihood_neg += loaded_log_prior\n",
    "\n",
    "    # Determine the predicted sentiment class\n",
    "    predicted_class = 1 if log_likelihood_pos > log_likelihood_neg else 0\n",
    "    return predicted_class\n",
    "\n",
    "# Input a new tweet\n",
    "new_tweet = input(\"Enter the tweet: \")\n",
    "\n",
    "# Preprocess the input tweet\n",
    "preprocessed_tweet = stemming(new_tweet)\n",
    "\n",
    "# Calculate log likelihood\n",
    "log_likelihood_pos, log_likelihood_neg = calculate_log_likelihood(preprocessed_tweet)\n",
    "\n",
    "# Make predictions\n",
    "predicted_sentiment = predict_sentiment(log_likelihood_pos, log_likelihood_neg)\n",
    "\n",
    "print(\"Your Entered Tweet : -\",new_tweet)\n",
    "\n",
    "# Display the result\n",
    "if predicted_sentiment == 1:\n",
    "    print(\"Positive sentiment!\")\n",
    "else:\n",
    "    print(\"Negative sentiment!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
